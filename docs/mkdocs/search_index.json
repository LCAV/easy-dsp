{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome\n\n\nThis project is a browser based interface for prototyping real-time processing algorithms using embedded multi channel audio acquisition platforms.\nThe interface allows to interact in an easy manner with a GNU/Linux enabled single board computer and to run algorithms in real-time on distant audio streams from a host computer.\nIt creates a bridge between the user's computer and the audio acquisition board.\n\n\nMore precisely, the interface permit to:\n\n\n\n\nchange the board configuration;\n\n\nwrite Python code;\n\n\nexecute it in real-time on the audio streams;\n\n\nvisualize data (typically outputs of the algorithm).\n\n\n\n\nThe project is composed of three main components, communicating together using WebSockets:\n\n\n\n\ndaemons in C running on the board: they transmit the audio streams and listen for configuration changes;\n\n\na Python daemon: it executes Python code sent by the interface;\n\n\nthe interface itself.\n\n\n\n\nFinally, a Python module helps the user to access the audio streams, the configuration, and to create data visualizations.\nThis module connects to the C daemons (to receive the streams and the configuration) and to the browser to send data in real-time for visualizations.\n\n\nThe repository of the project is here: \nhttps://github.com/LCAV/easy-dsp\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome", 
            "text": "This project is a browser based interface for prototyping real-time processing algorithms using embedded multi channel audio acquisition platforms.\nThe interface allows to interact in an easy manner with a GNU/Linux enabled single board computer and to run algorithms in real-time on distant audio streams from a host computer.\nIt creates a bridge between the user's computer and the audio acquisition board.  More precisely, the interface permit to:   change the board configuration;  write Python code;  execute it in real-time on the audio streams;  visualize data (typically outputs of the algorithm).   The project is composed of three main components, communicating together using WebSockets:   daemons in C running on the board: they transmit the audio streams and listen for configuration changes;  a Python daemon: it executes Python code sent by the interface;  the interface itself.   Finally, a Python module helps the user to access the audio streams, the configuration, and to create data visualizations.\nThis module connects to the C daemons (to receive the streams and the configuration) and to the browser to send data in real-time for visualizations.  The repository of the project is here:  https://github.com/LCAV/easy-dsp .", 
            "title": "Welcome"
        }, 
        {
            "location": "/getting-started/", 
            "text": "Getting Started\n\n\nOn the board\n\n\nInstallation\n\n\nPrerequisites\n\n\n\n\nlibwebsock\n;\n\n\nJansson\n;\n\n\nApache and PHP: \nsudo apt-get install apache2 libapache2-mod-php5 php5 php5-common\n.\n\n\n\n\nSetup\n\n\n\n\nClone the repository in \n/var/easy-dsp\n;\n\n\nCreate a file \n/var/easy-dsp/logs.txt\n and set the owner to \nwww-data\n;\n\n\nCopy the virtualhost configuration file and enable it;\n\n\nMake Apache listening on the port 8081;\n\n\nGive rights on audio devices to \nwww-data\n;\n\n\nCompile the C daemons.\n\n\n\n\nIn root, it resumes to:\n\n\ncd /var\ngit clone https://github.com/LCAV/easy-dsp\ncd easy-dsp\ntouch logs.txt\nchown www-data:www-data logs.txt api.php\nchmod 750 api.php\ncp microphones.virtualhost /etc/apache2/sites-available/microphones\na2ensite microphones\necho \nListen 8081\n \n /etc/apache2/ports.conf\nusermod -aG audio www-data\nsetfacl -m u:www-data:rw /dev/snd/*\nrm /tmp/micros-audio.socket /tmp/micros-control.socket\nservice apache2 restart\nmake\n\n\n\n\nOn the computer\n\n\nPrerequisites\n\n\n\n\nInstall \nws4py\n;\n\n\nNumpy.\n\n\n\n\nLaunch\n\n\n\n\nLaunch the Python daemon on your computer: \npython code-server.py\n;\n\n\nOpen your browser and access \nhttp://ip.of.the.board:8081\n;\n\n\nUsing the buttons on the interface, start the C daemons on the board;\n\n\nFinally write some code:\n\n\nYou can write code directly in the browser, where basics examples are provided;\n\n\nOr you can write a Python script with your favorite editor and launch it like any Python script:\n# The module browserinterface provides methods to access the audio streams in real-time,\n# change the configuration, record audio, and create data visualizations in the browser\nimport browserinterface\nimport random\n\nprint \"Simple program\"\n\n# First we define two data handlers: one line chart and one polar chart\nc1 = browserinterface.add_handler(\"First chart\", 'base:graph:line', {'xName': 'Duration', 'xLimitNb': 180, 'series': [{'name': 'Intensity 1'}, {'name':'Intensity 2'}]})\nc2 = browserinterface.add_handler(\"Polar\", 'base:polar:area', {'title': 'Direction', 'series': ['Intensity'], 'legend': {'from': 0, 'to': 360, 'step': 1}})\n\nc1.send_data({'add': [{'x': [1, 2, 3, 4], 'y': [89, 70, 40, 2, 3]}, {'x': [1, 2, 3, 4], 'y': [39, 20, -2, 4]}]})\n\ni = 4\n\n# This function will be called everytime a new audio buffer is available\n# buffer is a 2D-numpy array, described in the part Python Reference\ndef handle_buffer(buffer):\n    # print \"New buffer\", len(buffer)\n    global i\n    i += 1\n    # We send some random data\n    c1.send_data({'add': [{'x': [i], 'y': [20+i*5*random.random()]}, {'x': [i], 'y': [i*5*random.random()]}]})\n    c2.send_data([{'append': (200+i*3)*10}])\n\n# We register this function as a callback function, called every time a new audio buffer is received\nbrowserinterface.register_handle_data(handle_buffer)\n\ndef new_config_is_here(buffer_frames, rate, channels, volume):\n    print \"New config received: buffer_frames, rate, channels, volume\"\n    print buffer_frames, rate, channels, volume\n\n# We register our function so it will be called when a new configuration arrives\nbrowserinterface.register_when_new_config(new_config_is_here)\n\n# We start the module, so it will connect to the daemons to receive the audio stream\nbrowserinterface.start()\n\n# This call is blocking and will never return\n# So the code you put below will never be executed\n# It's an infinite loop inside which your callbacks will be called\nbrowserinterface.loop_callbacks()", 
            "title": "Getting started"
        }, 
        {
            "location": "/getting-started/#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#on-the-board", 
            "text": "", 
            "title": "On the board"
        }, 
        {
            "location": "/getting-started/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/getting-started/#prerequisites", 
            "text": "libwebsock ;  Jansson ;  Apache and PHP:  sudo apt-get install apache2 libapache2-mod-php5 php5 php5-common .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/getting-started/#setup", 
            "text": "Clone the repository in  /var/easy-dsp ;  Create a file  /var/easy-dsp/logs.txt  and set the owner to  www-data ;  Copy the virtualhost configuration file and enable it;  Make Apache listening on the port 8081;  Give rights on audio devices to  www-data ;  Compile the C daemons.   In root, it resumes to:  cd /var\ngit clone https://github.com/LCAV/easy-dsp\ncd easy-dsp\ntouch logs.txt\nchown www-data:www-data logs.txt api.php\nchmod 750 api.php\ncp microphones.virtualhost /etc/apache2/sites-available/microphones\na2ensite microphones\necho  Listen 8081    /etc/apache2/ports.conf\nusermod -aG audio www-data\nsetfacl -m u:www-data:rw /dev/snd/*\nrm /tmp/micros-audio.socket /tmp/micros-control.socket\nservice apache2 restart\nmake", 
            "title": "Setup"
        }, 
        {
            "location": "/getting-started/#on-the-computer", 
            "text": "", 
            "title": "On the computer"
        }, 
        {
            "location": "/getting-started/#prerequisites_1", 
            "text": "Install  ws4py ;  Numpy.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/getting-started/#launch", 
            "text": "Launch the Python daemon on your computer:  python code-server.py ;  Open your browser and access  http://ip.of.the.board:8081 ;  Using the buttons on the interface, start the C daemons on the board;  Finally write some code:  You can write code directly in the browser, where basics examples are provided;  Or you can write a Python script with your favorite editor and launch it like any Python script: # The module browserinterface provides methods to access the audio streams in real-time,\n# change the configuration, record audio, and create data visualizations in the browser\nimport browserinterface\nimport random\n\nprint \"Simple program\"\n\n# First we define two data handlers: one line chart and one polar chart\nc1 = browserinterface.add_handler(\"First chart\", 'base:graph:line', {'xName': 'Duration', 'xLimitNb': 180, 'series': [{'name': 'Intensity 1'}, {'name':'Intensity 2'}]})\nc2 = browserinterface.add_handler(\"Polar\", 'base:polar:area', {'title': 'Direction', 'series': ['Intensity'], 'legend': {'from': 0, 'to': 360, 'step': 1}})\n\nc1.send_data({'add': [{'x': [1, 2, 3, 4], 'y': [89, 70, 40, 2, 3]}, {'x': [1, 2, 3, 4], 'y': [39, 20, -2, 4]}]})\n\ni = 4\n\n# This function will be called everytime a new audio buffer is available\n# buffer is a 2D-numpy array, described in the part Python Reference\ndef handle_buffer(buffer):\n    # print \"New buffer\", len(buffer)\n    global i\n    i += 1\n    # We send some random data\n    c1.send_data({'add': [{'x': [i], 'y': [20+i*5*random.random()]}, {'x': [i], 'y': [i*5*random.random()]}]})\n    c2.send_data([{'append': (200+i*3)*10}])\n\n# We register this function as a callback function, called every time a new audio buffer is received\nbrowserinterface.register_handle_data(handle_buffer)\n\ndef new_config_is_here(buffer_frames, rate, channels, volume):\n    print \"New config received: buffer_frames, rate, channels, volume\"\n    print buffer_frames, rate, channels, volume\n\n# We register our function so it will be called when a new configuration arrives\nbrowserinterface.register_when_new_config(new_config_is_here)\n\n# We start the module, so it will connect to the daemons to receive the audio stream\nbrowserinterface.start()\n\n# This call is blocking and will never return\n# So the code you put below will never be executed\n# It's an infinite loop inside which your callbacks will be called\nbrowserinterface.loop_callbacks()", 
            "title": "Launch"
        }, 
        {
            "location": "/structure/", 
            "text": "Intro\n\n\nHere is the global structure of the project, and how the different parts interact.\n\n\nOverview\n\n\nThe system is divided in three parts:\n\n\n\n\nDaemons in C running on the board: they give access to the audio streams and listen for new configuration;\n\n\nA Python daemon running on the client computer: it executes the Python code sent by the browser;\n\n\nA webapp executed on the client computer: the interface itself.\n\n\n\n\nThese three parts communicate using \nWebSockets\n (basically a TCP connection, that you can use easily in Javascript, in browsers).\n\n\n\n\nAudio Distribution\n\n\nThere are three daemons running on the board, all in C (which form the first part):\n\n\n\n\nThe \nmain-daemon\n is the main part of the system, and the only one interacting with the microphones through ALSA API. It reads audio buffers and send them to WSAudio through a UNIX socket;\n\n\nThe WSAudio is a first bridge between the main daemon and a WebSocket, allowing external clients to access the audio streams;\n\n\nThe WSConfig is a second bridge between the main daemon and a WebSocket, allowing external clients to change the configuration of the microphones.\n\n\n\n\nThese three daemons communicate together using TCP connections over UNIX sockets.\n\n\n\n\nThe Main daemon\n\n\nThis daemon can receive in real-time the audio streams from the microphones using ALSA API, and can also send a new configuration using the same API.\nThen it listens on two UNIX sockets using TCP: \n/tmp/micros-audio.socket\n and \n/tmp/micros-control.socket\n.\n\n\nIt sends the audio stream to every client connected to the first socket, and can receive a new audio configuration from the second socket.\nThe idea is to provide the most basic functionnalities with this daemon, that can be extended using other programs which communicate with it using these two UNIX sockets.\n\n\nWSAudio\n\n\nThe WSAudio daemon connects to the main daemon using the UNIX socket \n/tmp/micros-audio.socket\n, so it receives the audio streams in real-time.\nIt also listens on the port 7321 using WebSocket.\nIt will send the audio streams it receives to every connected client as binary messages.\nIt doesn't keep in memory the frames: each time it receives new data from the main daemon, it sends it to the connected clients.\nHowever, the buffer sent by the main daemon through the UNIX socket may be fragmented (if the number of frames in one buffer is too large).\nWSAudio will rebuild the initial buffer from the multiple packets it received, before sending it to the WebSocket clients (the WebSocket protocol taking care of the fragmentation).\nWhen a new client arrives, it starts to receive the audio streams from this moment.\n\n\nWSConfig\n\n\nThe WSConfig daemon connects to the main daemon using the UNIX socket \n/tmp/micros-control.socket\n.\nIt also listens on the port 7322 using WebSocket.\nWhen a client sends to it a configuration (using a text message containing JSON), it reads the JSON and sends the new information (using an array of integers) to the main daemon.\nThe main daemon will then interrupt its connection with ALSA, set the new configuration it just received and start again to receive the audio stream.\n\n\nInterface and code execution\n\n\nFor code execution, a Python daemon \ncode-server.py\n listens on a WebSocket and executes the Python code it receives on it. The daemon can either run on the user's computer or on the board (if enough powerful), or even on a server.\n\n\nThe interface reduces to the page \nclient.html\n, which connects to WSAudio and WSConfig so the user can listen to the audio streams and change the configuration, and also to the Python daemon to which it can send Python code written by the user.\nThis code, once executed, may connect to the browser so it can send it data for visualization.\n\n\nExecution of Python code from the browser\n\n\nIn the webapp, there is an editor where the user can write some Python code.\nWhen he/she clicks on \nExecute\n the code is sent to the local Python daemon.\nThen the Python daemon includes the code to an existing Python program, \nbase-program.py\n (at the end, it replaces the line \n#####INSERT: Here insert code\n with the code from the user), and executes it.\n\n\nThis new Python program will then connect to WSAudio, so it will receive the audio streams in real-time (and executes the code from the user on it), and it will also listen on a WebSocket (on a port around 7320 specified by the Python daemon, which communicated it to the webapp) to which the webapp will connect.\nSo this new Python program will have the possibility to work on the audio streams and to send the output (which can be plots data or a new audio stream) directly to the webapp.\nThe webapp also uses this connection to send the IP address of the board, so the Python script knows how to connect to WSAudio.\n\n\nMore precisely, the user is invited to write her code inside a function (for example \nmy_handle_data(buffer)\n) and to register it as a callback (using \nbrowserinterface.register_handle_data(my_handle_data)\n) so it will be called every time a new audio buffer is received from the WSAudio daemon.\n\n\nThe Python daemon will also catch the \nstdout\n and \nstderr\n streams and redirect them to the browser, so the user can easily access it.\n\n\n\n\nExecution of a Python script\n\n\nIt is also possible to write a Python script, that will use the library of the project to easily receive the audio, and to send output to the browser (if wanted).\nIn that cas the browser is just used as a vizualisation tool.\nJust as previously, the script will connect to WSAudio and receive in real-time the audio streams.\n\n\nHowever, this time, the outputs are not redirected, so you will be able to see them directly in your console, like any Python script.\nThe library will also choose a port around 7320 by itself, and will communicate it to the Python daemon, which will send it to the browser, so this last one can connects to the Python script and receive the output (plots or new audio stream).\n\n\nYou can also decide you don't need the browser and just use the connection to the audio stream, and any vizualisation library you want.", 
            "title": "Structure"
        }, 
        {
            "location": "/structure/#intro", 
            "text": "Here is the global structure of the project, and how the different parts interact.", 
            "title": "Intro"
        }, 
        {
            "location": "/structure/#overview", 
            "text": "The system is divided in three parts:   Daemons in C running on the board: they give access to the audio streams and listen for new configuration;  A Python daemon running on the client computer: it executes the Python code sent by the browser;  A webapp executed on the client computer: the interface itself.   These three parts communicate using  WebSockets  (basically a TCP connection, that you can use easily in Javascript, in browsers).", 
            "title": "Overview"
        }, 
        {
            "location": "/structure/#audio-distribution", 
            "text": "There are three daemons running on the board, all in C (which form the first part):   The  main-daemon  is the main part of the system, and the only one interacting with the microphones through ALSA API. It reads audio buffers and send them to WSAudio through a UNIX socket;  The WSAudio is a first bridge between the main daemon and a WebSocket, allowing external clients to access the audio streams;  The WSConfig is a second bridge between the main daemon and a WebSocket, allowing external clients to change the configuration of the microphones.   These three daemons communicate together using TCP connections over UNIX sockets.", 
            "title": "Audio Distribution"
        }, 
        {
            "location": "/structure/#the-main-daemon", 
            "text": "This daemon can receive in real-time the audio streams from the microphones using ALSA API, and can also send a new configuration using the same API.\nThen it listens on two UNIX sockets using TCP:  /tmp/micros-audio.socket  and  /tmp/micros-control.socket .  It sends the audio stream to every client connected to the first socket, and can receive a new audio configuration from the second socket.\nThe idea is to provide the most basic functionnalities with this daemon, that can be extended using other programs which communicate with it using these two UNIX sockets.", 
            "title": "The Main daemon"
        }, 
        {
            "location": "/structure/#wsaudio", 
            "text": "The WSAudio daemon connects to the main daemon using the UNIX socket  /tmp/micros-audio.socket , so it receives the audio streams in real-time.\nIt also listens on the port 7321 using WebSocket.\nIt will send the audio streams it receives to every connected client as binary messages.\nIt doesn't keep in memory the frames: each time it receives new data from the main daemon, it sends it to the connected clients.\nHowever, the buffer sent by the main daemon through the UNIX socket may be fragmented (if the number of frames in one buffer is too large).\nWSAudio will rebuild the initial buffer from the multiple packets it received, before sending it to the WebSocket clients (the WebSocket protocol taking care of the fragmentation).\nWhen a new client arrives, it starts to receive the audio streams from this moment.", 
            "title": "WSAudio"
        }, 
        {
            "location": "/structure/#wsconfig", 
            "text": "The WSConfig daemon connects to the main daemon using the UNIX socket  /tmp/micros-control.socket .\nIt also listens on the port 7322 using WebSocket.\nWhen a client sends to it a configuration (using a text message containing JSON), it reads the JSON and sends the new information (using an array of integers) to the main daemon.\nThe main daemon will then interrupt its connection with ALSA, set the new configuration it just received and start again to receive the audio stream.", 
            "title": "WSConfig"
        }, 
        {
            "location": "/structure/#interface-and-code-execution", 
            "text": "For code execution, a Python daemon  code-server.py  listens on a WebSocket and executes the Python code it receives on it. The daemon can either run on the user's computer or on the board (if enough powerful), or even on a server.  The interface reduces to the page  client.html , which connects to WSAudio and WSConfig so the user can listen to the audio streams and change the configuration, and also to the Python daemon to which it can send Python code written by the user.\nThis code, once executed, may connect to the browser so it can send it data for visualization.", 
            "title": "Interface and code execution"
        }, 
        {
            "location": "/structure/#execution-of-python-code-from-the-browser", 
            "text": "In the webapp, there is an editor where the user can write some Python code.\nWhen he/she clicks on  Execute  the code is sent to the local Python daemon.\nThen the Python daemon includes the code to an existing Python program,  base-program.py  (at the end, it replaces the line  #####INSERT: Here insert code  with the code from the user), and executes it.  This new Python program will then connect to WSAudio, so it will receive the audio streams in real-time (and executes the code from the user on it), and it will also listen on a WebSocket (on a port around 7320 specified by the Python daemon, which communicated it to the webapp) to which the webapp will connect.\nSo this new Python program will have the possibility to work on the audio streams and to send the output (which can be plots data or a new audio stream) directly to the webapp.\nThe webapp also uses this connection to send the IP address of the board, so the Python script knows how to connect to WSAudio.  More precisely, the user is invited to write her code inside a function (for example  my_handle_data(buffer) ) and to register it as a callback (using  browserinterface.register_handle_data(my_handle_data) ) so it will be called every time a new audio buffer is received from the WSAudio daemon.  The Python daemon will also catch the  stdout  and  stderr  streams and redirect them to the browser, so the user can easily access it.", 
            "title": "Execution of Python code from the browser"
        }, 
        {
            "location": "/structure/#execution-of-a-python-script", 
            "text": "It is also possible to write a Python script, that will use the library of the project to easily receive the audio, and to send output to the browser (if wanted).\nIn that cas the browser is just used as a vizualisation tool.\nJust as previously, the script will connect to WSAudio and receive in real-time the audio streams.  However, this time, the outputs are not redirected, so you will be able to see them directly in your console, like any Python script.\nThe library will also choose a port around 7320 by itself, and will communicate it to the Python daemon, which will send it to the browser, so this last one can connects to the Python script and receive the output (plots or new audio stream).  You can also decide you don't need the browser and just use the connection to the audio stream, and any vizualisation library you want.", 
            "title": "Execution of a Python script"
        }, 
        {
            "location": "/messages-ref/", 
            "text": "Intro\n\n\nHere you will find the different messages that can be exchanged between the different components, inside the UNIX Sockets or the WebSockets.\nThe titles are always server \n client.\n\n\nMain Daemon\n\n\nMain Daemon \n WSAudio\n\n\nThis connection is only one-way: the main daemon sends messages to WSAudio.\n\n\nConnection\n\n\n\n\nSocket Type: UNIX Socket;\n\n\nFile: \n/tmp/micros-audio.socket\n;\n\n\nTransport protocol: TCP.\n\n\n\n\nMessages\n\n\n\n\nAudio configuration: this message allows WSAudio to know the audio configuration choosed, so that it can allocate the correct buffer size.\n\n\nLength in \nbytes\n: \n4*sizeof(int)\n;\n\n\nPayload: four integer: \n{buffer_frames}{rate}{channels}{volume}\n:\n\n\nbuffer_frames\n: number of audio frames in one buffer;\n\n\nrate\n: audio rate (in bits/second);\n\n\nchannels\n: number of channels;\n\n\nvolume\n: ALSA volume of all microphones, between 0 and 100.\n\n\n\n\n\n\nSo the size of the audio buffer is \nbuffer_size = buffer_frames*channels*sizeof(SND_PCM_FORMAT_S16_LE) / 8\n in \nbytes\n (for now, one audio frame is encoded with a 16-bits little-endian integer).\n\n\n\n\n\n\nAudio buffer: this message contains new audio data.\n\n\nLength: the previous computed \nbuffer_size\n;\n\n\nPayload: \nbuffer_frames*channels\n 16-bits little-endian integer, in the following order (for example with 2 channels):\n\n\nframes[0].channels[0];\n\n\nframes[0].channels[1];\n\n\nframes[1].channels[0];\n\n\nframes[1].channels[1];\n\n\nframes[2].channels[0];\n\n\nframes[2].channels[1];\n\n\n...\n\n\n\n\n\n\n\n\n\n\n\n\nTo differentiate the two messages types, WSAudio only uses the length of the message.\nIf it's four integers then it is a configuration information, else it is audio data.\n\n\nMain Daemon \n WSConfig\n\n\nThis connection is only one-way: WSConfig sends messages to the main daemon.\n\n\nConnection\n\n\n\n\nSocket Type: UNIX Socket;\n\n\nFile: \n/tmp/micros-config.socket\n;\n\n\nTransport protocol: TCP.\n\n\n\n\nMessages\n\n\n\n\nAudio configuration: this message allows WSConfig to send a new audio configuration to the main daemon.\n\n\nLength in \nbytes\n: \n4*sizeof(int)\n;\n\n\nPayload: four integer: \n{buffer_frames}{rate}{channels}{volume}\n:\n\n\nbuffer_frames\n: number of audio frames in one buffer;\n\n\nrate\n: audio rate (in bits/second);\n\n\nchannels\n: number of channels;\n\n\nvolume\n: ALSA volume of all microphones, between 0 and 100.\n\n\n\n\n\n\n\n\n\n\n\n\nWSAudio \n Client\n\n\nThis connection is only one-way: WSAudio sends messages to the webapp or the Python program.\n\n\nConnection\n\n\n\n\nProtocol: WebSocket;\n\n\nPort: 7321.\n\n\n\n\nMessages\n\n\n\n\n\n\nAudio configuration: this message allows the client to know the audio configuration chosen.\n\n\n\n\nMessage type: text;\n\n\n\n\nMessage format: JSON:\n\n\n{\n  \"buffer_frames\": (integer), // the number of frames in one buffer\n  \"rate\": (integer), // the bitrate in bits/second\n  \"channels\": (integer), // the number of channels\n  \"volume\": (integer) // the volume of all microphones, between 0 and 100\n}\n\n\n\n\n\n\n\nSo the size of the audio buffer is \nm.buffer_frames * m.channels * 16 / 8\n in \nbytes\n (16 because a frame is encoded using a 16-bits little-endian integer), where \nm\n is the received JSON message.\n\n\n\n\n\n\n\n\n\n\nAudio buffer: this message contains new audio data.\n\n\n\n\nMessage type: binary;\n\n\nPayload: \nm.buffer_frames * m.channels\n 16-bits little-endian integer, in the following order (for example with 2 channels):\n\n\nframes[0].channels[0];\n\n\nframes[0].channels[1];\n\n\nframes[1].channels[0];\n\n\nframes[1].channels[1];\n\n\nframes[2].channels[0];\n\n\nframes[2].channels[1];\n\n\n...\n\n\n\n\n\n\n\n\n\n\n\n\nWSConfig \n Webapp\n\n\nThis connection is only one-way: the webapp sends new audio configuration to WSConfig\n\n\nConnection\n\n\n\n\nProtocol: WebSocket;\n\n\nPort: 7322.\n\n\n\n\nMessages\n\n\n\n\nAudio configuration: this message allows the webapp to send a new audio configuration to WSConfig.\n\n\nMessage type: text;\n\n\nMessage format: JSON:\n{\n  \"buffer_frames\": (integer), // the number of frames in one buffer\n  \"rate\": (integer), // the bitrate in bits/second\n  \"channels\": (integer), // the number of channels\n  \"volume\": (integer) // the volume of all microphones, between 0 and 100\n}\n\n\n\n\n\n\n\n\n\n\n\nPython Daemon \n Webapp\n\n\nThis conenction is two-ways: the webapp can send new Python code to execute, and the daemon can send back the status of the program.\n\n\nConnection (server: Python Daemon)\n\n\n\n\nProtocol: WebSocket;\n\n\nPort: 7320.\n\n\n\n\nMessages: Webapp \n Python Daemon\n\n\n\n\n\n\nIP address of the board.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"board\": (string)}\n\n\n\n\n\n\n\n\nPython code to execute: this message contains new Python code to insert into \nbase-program.py\n and to execute.\n\n\n\n\nMessage type: text;\n\n\nPayload: just the Python code to execute.\n\n\n\n\n\n\n\n\nInterruption of the running code: this messages asks the daemon to stop the current Python code running (each client can only have one Python program running at each time).\n\n\n\n\nMessage type: text;\n\n\nPayload: just \nSTOP\n.\n\n\n\n\n\n\n\n\nMessages: Python Daemon \n Webapp\n\n\n\n\n\n\nPort information: this message indicates to the webapp on which port the new Python program will listen for its WebSocket.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"port\": (integer)}\n.\n\n\n\n\n\n\n\n\nStdout new line: this message is sent to the webapp each time the new Python program outputs a line on stdout.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"line\": (string)}\n.\n\n\n\n\n\n\n\n\nStderr new line: this message is sent to the webapp each time the new Python program outputs a line on stderr.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"error\": (string)}\n.\n\n\n\n\n\n\n\n\nLine inserted: this message indicates to the webapp on which line of \nbase-program.py\n the Python code has been inserted (it is usefull to find the correspondance between an error and the original line).\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"codeLine\": (integer)}\n.\n\n\n\n\n\n\n\n\nEnd of the Python program: this message is sent to the webapp when the new Python program exits, with the code returned.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"status\": \"end\", \"code\": (integer)}\n.\n\n\n\n\n\n\n\n\nNew script: this message indicates to the webapp that a Python script is running and would like to use the webapp for display, and specify on which port the Python program listens for its WebSocket.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"script\": (integer)}\n.\n\n\n\n\n\n\n\n\nPython Daemon \n final-program.py\n\n\nConnection (server: Python Daemon)\n\n\n\n\nProtocol: WebSocket;\n\n\nPort: 7320.\n\n\n\n\nMessages: Python Daemon \n final-program.py\n\n\n\n\nIP address of the board.\n\n\nMessage type: text;\n\n\nMessage format: \n(string)\n\n\n\n\n\n\n\n\nMessages: final-program.py \n Python Daemon\n\n\n\n\nNew script: this message indicates to the Python Daemon that a Python script is running and would like to use the webapp for display, and specify on which port the Python program listens for its WebSocket. The Python Daemon will then inform the browser.\n\n\nMessage type: text;\n\n\nMessage format: JSON: \n{\"script\": (string)}\n.\n\n\n\n\n\n\n\n\nfinal-program.py \n Webapp\n\n\nThis connection is one-way only: the new Python program can send various outputs to the webapp.\n\n\nConnection\n\n\n\n\nProtocol: WebSocket;\n\n\nPort: just over 7320 (choosen and specified by the Python daemon).\n\n\n\n\nMessages\n\n\n\n\n\n\nAudio data to play: this message contains a new audio buffer. The Python program can for example perform something on the audio stream and outputs a new audio stream it wants the webapp to play.\n\n\n\n\nMessage type: binary;\n\n\nPayload: for now, the configuration must be the same as the input stream: \ninput_conf.buffer_frames * input_conf.channels\n 16-bits little-endian integer, in the following order (for example with 2 channels):\n\n\nframes[0].channels[0];\n\n\nframes[0].channels[1];\n\n\nframes[1].channels[0];\n\n\nframes[1].channels[1];\n\n\nframes[2].channels[0];\n\n\nframes[2].channels[1];\n\n\n...\n\n\n\n\n\n\n\n\n\n\n\n\nAudio latency: this message contains the delay in milliseconds between the processing and the reality. We just measure how much time elapsed between the first audio frame we received, and the audio duration we received.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON:\n{\n    \"latency\": (float)\n}\n\n\n\n\n\n\n\n\n\n\n\nCreation of a new data handler: this message asks the webapp to create a new data handler, that will be then filled with new data.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON:\n{\n    \"addHandler\": (string), // name of the handler for display\n    \"id\": (integer), // id chosen to identify the handler. Must be unique\n    \"type\": (string), // type of handler\n    \"parameters\": (object) // optional parameters\n}\n\n\n\n\n\n\n\n\n\n\n\nNew data for a data handler: this message contains new data for an existing data handler.\n\n\n\n\nMessage type: text;\n\n\nMessage format: JSON:\n{\n    \"dataHandler\": (integer), // id of the existing data handler\n    \"data\": (object) // data for the existing data handler\n}", 
            "title": "Messages reference"
        }, 
        {
            "location": "/messages-ref/#intro", 
            "text": "Here you will find the different messages that can be exchanged between the different components, inside the UNIX Sockets or the WebSockets.\nThe titles are always server   client.", 
            "title": "Intro"
        }, 
        {
            "location": "/messages-ref/#main-daemon", 
            "text": "", 
            "title": "Main Daemon"
        }, 
        {
            "location": "/messages-ref/#main-daemon-wsaudio", 
            "text": "This connection is only one-way: the main daemon sends messages to WSAudio.", 
            "title": "Main Daemon &gt; WSAudio"
        }, 
        {
            "location": "/messages-ref/#connection", 
            "text": "Socket Type: UNIX Socket;  File:  /tmp/micros-audio.socket ;  Transport protocol: TCP.", 
            "title": "Connection"
        }, 
        {
            "location": "/messages-ref/#messages", 
            "text": "Audio configuration: this message allows WSAudio to know the audio configuration choosed, so that it can allocate the correct buffer size.  Length in  bytes :  4*sizeof(int) ;  Payload: four integer:  {buffer_frames}{rate}{channels}{volume} :  buffer_frames : number of audio frames in one buffer;  rate : audio rate (in bits/second);  channels : number of channels;  volume : ALSA volume of all microphones, between 0 and 100.    So the size of the audio buffer is  buffer_size = buffer_frames*channels*sizeof(SND_PCM_FORMAT_S16_LE) / 8  in  bytes  (for now, one audio frame is encoded with a 16-bits little-endian integer).    Audio buffer: this message contains new audio data.  Length: the previous computed  buffer_size ;  Payload:  buffer_frames*channels  16-bits little-endian integer, in the following order (for example with 2 channels):  frames[0].channels[0];  frames[0].channels[1];  frames[1].channels[0];  frames[1].channels[1];  frames[2].channels[0];  frames[2].channels[1];  ...       To differentiate the two messages types, WSAudio only uses the length of the message.\nIf it's four integers then it is a configuration information, else it is audio data.", 
            "title": "Messages"
        }, 
        {
            "location": "/messages-ref/#main-daemon-wsconfig", 
            "text": "This connection is only one-way: WSConfig sends messages to the main daemon.", 
            "title": "Main Daemon &lt; WSConfig"
        }, 
        {
            "location": "/messages-ref/#connection_1", 
            "text": "Socket Type: UNIX Socket;  File:  /tmp/micros-config.socket ;  Transport protocol: TCP.", 
            "title": "Connection"
        }, 
        {
            "location": "/messages-ref/#messages_1", 
            "text": "Audio configuration: this message allows WSConfig to send a new audio configuration to the main daemon.  Length in  bytes :  4*sizeof(int) ;  Payload: four integer:  {buffer_frames}{rate}{channels}{volume} :  buffer_frames : number of audio frames in one buffer;  rate : audio rate (in bits/second);  channels : number of channels;  volume : ALSA volume of all microphones, between 0 and 100.", 
            "title": "Messages"
        }, 
        {
            "location": "/messages-ref/#wsaudio-client", 
            "text": "This connection is only one-way: WSAudio sends messages to the webapp or the Python program.", 
            "title": "WSAudio &gt; Client"
        }, 
        {
            "location": "/messages-ref/#connection_2", 
            "text": "Protocol: WebSocket;  Port: 7321.", 
            "title": "Connection"
        }, 
        {
            "location": "/messages-ref/#messages_2", 
            "text": "Audio configuration: this message allows the client to know the audio configuration chosen.   Message type: text;   Message format: JSON:  {\n  \"buffer_frames\": (integer), // the number of frames in one buffer\n  \"rate\": (integer), // the bitrate in bits/second\n  \"channels\": (integer), // the number of channels\n  \"volume\": (integer) // the volume of all microphones, between 0 and 100\n}    So the size of the audio buffer is  m.buffer_frames * m.channels * 16 / 8  in  bytes  (16 because a frame is encoded using a 16-bits little-endian integer), where  m  is the received JSON message.      Audio buffer: this message contains new audio data.   Message type: binary;  Payload:  m.buffer_frames * m.channels  16-bits little-endian integer, in the following order (for example with 2 channels):  frames[0].channels[0];  frames[0].channels[1];  frames[1].channels[0];  frames[1].channels[1];  frames[2].channels[0];  frames[2].channels[1];  ...", 
            "title": "Messages"
        }, 
        {
            "location": "/messages-ref/#wsconfig-webapp", 
            "text": "This connection is only one-way: the webapp sends new audio configuration to WSConfig", 
            "title": "WSConfig &lt; Webapp"
        }, 
        {
            "location": "/messages-ref/#connection_3", 
            "text": "Protocol: WebSocket;  Port: 7322.", 
            "title": "Connection"
        }, 
        {
            "location": "/messages-ref/#messages_3", 
            "text": "Audio configuration: this message allows the webapp to send a new audio configuration to WSConfig.  Message type: text;  Message format: JSON: {\n  \"buffer_frames\": (integer), // the number of frames in one buffer\n  \"rate\": (integer), // the bitrate in bits/second\n  \"channels\": (integer), // the number of channels\n  \"volume\": (integer) // the volume of all microphones, between 0 and 100\n}", 
            "title": "Messages"
        }, 
        {
            "location": "/messages-ref/#python-daemon-webapp", 
            "text": "This conenction is two-ways: the webapp can send new Python code to execute, and the daemon can send back the status of the program.", 
            "title": "Python Daemon &lt;&gt; Webapp"
        }, 
        {
            "location": "/messages-ref/#connection-server-python-daemon", 
            "text": "Protocol: WebSocket;  Port: 7320.", 
            "title": "Connection (server: Python Daemon)"
        }, 
        {
            "location": "/messages-ref/#messages-webapp-python-daemon", 
            "text": "IP address of the board.   Message type: text;  Message format: JSON:  {\"board\": (string)}     Python code to execute: this message contains new Python code to insert into  base-program.py  and to execute.   Message type: text;  Payload: just the Python code to execute.     Interruption of the running code: this messages asks the daemon to stop the current Python code running (each client can only have one Python program running at each time).   Message type: text;  Payload: just  STOP .", 
            "title": "Messages: Webapp &gt; Python Daemon"
        }, 
        {
            "location": "/messages-ref/#messages-python-daemon-webapp", 
            "text": "Port information: this message indicates to the webapp on which port the new Python program will listen for its WebSocket.   Message type: text;  Message format: JSON:  {\"port\": (integer)} .     Stdout new line: this message is sent to the webapp each time the new Python program outputs a line on stdout.   Message type: text;  Message format: JSON:  {\"line\": (string)} .     Stderr new line: this message is sent to the webapp each time the new Python program outputs a line on stderr.   Message type: text;  Message format: JSON:  {\"error\": (string)} .     Line inserted: this message indicates to the webapp on which line of  base-program.py  the Python code has been inserted (it is usefull to find the correspondance between an error and the original line).   Message type: text;  Message format: JSON:  {\"codeLine\": (integer)} .     End of the Python program: this message is sent to the webapp when the new Python program exits, with the code returned.   Message type: text;  Message format: JSON:  {\"status\": \"end\", \"code\": (integer)} .     New script: this message indicates to the webapp that a Python script is running and would like to use the webapp for display, and specify on which port the Python program listens for its WebSocket.   Message type: text;  Message format: JSON:  {\"script\": (integer)} .", 
            "title": "Messages: Python Daemon &gt; Webapp"
        }, 
        {
            "location": "/messages-ref/#python-daemon-final-programpy", 
            "text": "", 
            "title": "Python Daemon &lt;&gt; final-program.py"
        }, 
        {
            "location": "/messages-ref/#connection-server-python-daemon_1", 
            "text": "Protocol: WebSocket;  Port: 7320.", 
            "title": "Connection (server: Python Daemon)"
        }, 
        {
            "location": "/messages-ref/#messages-python-daemon-final-programpy", 
            "text": "IP address of the board.  Message type: text;  Message format:  (string)", 
            "title": "Messages: Python Daemon &gt; final-program.py"
        }, 
        {
            "location": "/messages-ref/#messages-final-programpy-python-daemon", 
            "text": "New script: this message indicates to the Python Daemon that a Python script is running and would like to use the webapp for display, and specify on which port the Python program listens for its WebSocket. The Python Daemon will then inform the browser.  Message type: text;  Message format: JSON:  {\"script\": (string)} .", 
            "title": "Messages: final-program.py &gt; Python Daemon"
        }, 
        {
            "location": "/messages-ref/#final-programpy-webapp", 
            "text": "This connection is one-way only: the new Python program can send various outputs to the webapp.", 
            "title": "final-program.py &gt; Webapp"
        }, 
        {
            "location": "/messages-ref/#connection_4", 
            "text": "Protocol: WebSocket;  Port: just over 7320 (choosen and specified by the Python daemon).", 
            "title": "Connection"
        }, 
        {
            "location": "/messages-ref/#messages_4", 
            "text": "Audio data to play: this message contains a new audio buffer. The Python program can for example perform something on the audio stream and outputs a new audio stream it wants the webapp to play.   Message type: binary;  Payload: for now, the configuration must be the same as the input stream:  input_conf.buffer_frames * input_conf.channels  16-bits little-endian integer, in the following order (for example with 2 channels):  frames[0].channels[0];  frames[0].channels[1];  frames[1].channels[0];  frames[1].channels[1];  frames[2].channels[0];  frames[2].channels[1];  ...       Audio latency: this message contains the delay in milliseconds between the processing and the reality. We just measure how much time elapsed between the first audio frame we received, and the audio duration we received.   Message type: text;  Message format: JSON: {\n    \"latency\": (float)\n}      Creation of a new data handler: this message asks the webapp to create a new data handler, that will be then filled with new data.   Message type: text;  Message format: JSON: {\n    \"addHandler\": (string), // name of the handler for display\n    \"id\": (integer), // id chosen to identify the handler. Must be unique\n    \"type\": (string), // type of handler\n    \"parameters\": (object) // optional parameters\n}      New data for a data handler: this message contains new data for an existing data handler.   Message type: text;  Message format: JSON: {\n    \"dataHandler\": (integer), // id of the existing data handler\n    \"data\": (object) // data for the existing data handler\n}", 
            "title": "Messages"
        }, 
        {
            "location": "/python-reference/", 
            "text": "Intro\n\n\nThis part explains how to get the audio streams in Python code and how to send results to the webapp, so it can display them in live.\n\n\nHow it works\n\n\nWhen you write code in the webapp editor and click \"Execute\", it will be executed as a new Python script.\nSo either you use the browser or write directly a Python script that you launch from your terminal, the way it works is similar.\n\n\nTo easily access the audio streams, and display something in the webapp, we provide a Python module \nbrowserinterface\n.\n\n\nThe minimum Python code is the following:\n\n\n# First you import the module\nimport browserinterface\n\n# Then you define the function that will perform some algorithm on the audio streams\ndef handle(buffer):\n    print \nBuffer received\n, len(buffer)\n\n\n# Finally you register your function, so browserinterface will call it every time a new audio buffer is received,\nbrowserinterface.register_handle_data(handle)\n# You start the module, so it will connects to WSAudio, and listen so the browser will be able to connect\nbrowserinterface.start()\n\n# Finally you start the callbacks blocking infinite loop\n# All code below will not be executed\n# This mecanism ensures the callbacks you specified are called from the main thread\n# If you forget this call, your callbacks will never be called!\nbrowserinterface.loop_callbacks()\n\n\n\n\nIn the following, when we talk about functions and variables, they all come from the module \nbrowserinterface\n, so you must prefix them with \nbrowserinterface.\n.\n\n\nIf the browser is not needed\n\n\nIf you run your own Python script and don't need the browser (to display the output), you have to set the variable \ninform_browser\n to false.\nIn that case, you also have to specify the IP address of the board, using the variable \nboard_ip\n (when you use the browser, it directly communicate to your script the IP address of the board, so you don't need to specify it).\n\n\nbrowserinterface.inform_browser = False\nbrowserinterface.board_ip = '10.1.2.3'\n\n\n\n\nThis must be done at the very beginning, before you \nstart()\n the module.\n\n\nReading the configuration\n\n\nFour variables contain the configuration:\n\n\n\n\nrate\n: the rate in bits/second;\n\n\nchannels\n: the number of channels;\n\n\nbuffer_frames\n: the number of audio frames contained in one buffer;\n\n\nvolume\n: the volume between 0 and 100.\n\n\n\n\nThese are read-only, and you must not change them.\n\n\nReceiving configuration changes\n\n\nWhen you start your script, the four previous variables will still be uninitialized, because the module did not received the configuration yet.\nPlus, sometimes, a configuration change can happen.\n\n\nYou can register a callback to receive the configuration, when it first arrives, and each time it changes, using \nregister_when_new_config(callback)\n.\nYour callback function must accept four parameters: \ncallback(buffer_frames, rate, channels, volume)\n.\n\n\nIf you have some variables to initialize, depending on the audio configuration, \nit is safer to do it in your callback\n.\n\n\ndef my_function(buffer_frames, rate, channels, volume):\n    print \nNew config received: buffer_frames, rate, channels, volume\n\n    print buffer_frames, rate, channels, volume\n\nbrowserinterface.register_when_new_config(my_function)\n\n\n\n\nChanging the configuration\n\n\nYou can change the configuration using the method \nchange_config(rate, channels, buffer_frames, volume)\n.\n\n\nbrowserinterface.change_config(rate=44100, channels=2, buffer_frames=2048, volume=90)\n\n\n\n\nReceiving the audio streams\n\n\nYou can define a function that will be called each time a new audio buffer is received, by registering it:\n\n\ndef my_function(buffer):\n    print \nBuffer received\n, len(buffer)\nbrowserinterface.register_handle_data(my_function)\n\n\n\n\nThe parameter \nbuffer\n will contain a 2D numpy array of size \n(buffer_frames, channels)\n containing 16 bits integers (between -32 767 and +32 767).\n\n\nAn example with 5 frames per buffer and 2 channels:\n\n\nnp.array([\n  [100, 300],\n  [80, 240],\n  [130, 0],\n  [-800, 123],\n  [-400, 0]\n], dtype=np.int16)\n\n\n\n\nRecording audio\n\n\nYou can ask the Python module to record a certain audio duration for you, and to call the callback you specified, using the method \nrecord_audio(duration, callback)\n with \nduration\n in milliseconds.\nThe recording starts just after you called the method.\n\n\nThe function \ncallback\n you specified must accept one parameter \nbuffer\n (which will follow the same structure than above).\nPay attention that \nbuffer\n will not be exactly of the duration you specified, but can be slightly longer.\n\n\ndef my_function(buffer):\n    print \nAudio has been recorded\n, len(buffer)\n\nbrowserinterface.record_audio(5000, my_function) # my_function will be called after 5 seconds\nbrowserinterface.record_audio(15000, my_function) # my_function will be called after 15 seconds\n\n\n\n\nSending audio\n\n\nIt is possible to send a new audio stream to the browser so it will play it.\nThe configuration must be exactly the same as the input buffer (same number of channels, same rate, same number of frames per buffer).\n\n\nThe method \nsend_audio(buffer)\n accepts a 2D Numpy array, following the same format as the input.\n\n\nUsing the data handlers\n\n\nAfter you performed some algorithms on the audio streams, you may want to display some outputs, like charts, histograms or new audio streams.\nWhat you have to do is to send the data you want to display to a \ndata handler\n of the webapp.\nYou have two simple steps to do:\n\n\n\n\nYou create a new data handler using the function \nadd_handler(name, type, parameters)\n which returns an object representing this new instance;\n\n\nYou send data to this instance using its method \nsend_data(data)\n.\n\n\n\n\nOnce you call the function \nadd_handler\n, a new tab will be created in the webapp, with the name \nname\n you specified, and the chart/plot/audio player will appear inside.\nYou can use the part \nData Handlers\n to see which \ntypes\n of data handlers exist, which parameters are supported, and which structure the \ndata\n you send must follow.", 
            "title": "Python reference"
        }, 
        {
            "location": "/python-reference/#intro", 
            "text": "This part explains how to get the audio streams in Python code and how to send results to the webapp, so it can display them in live.", 
            "title": "Intro"
        }, 
        {
            "location": "/python-reference/#how-it-works", 
            "text": "When you write code in the webapp editor and click \"Execute\", it will be executed as a new Python script.\nSo either you use the browser or write directly a Python script that you launch from your terminal, the way it works is similar.  To easily access the audio streams, and display something in the webapp, we provide a Python module  browserinterface .  The minimum Python code is the following:  # First you import the module\nimport browserinterface\n\n# Then you define the function that will perform some algorithm on the audio streams\ndef handle(buffer):\n    print  Buffer received , len(buffer)\n\n\n# Finally you register your function, so browserinterface will call it every time a new audio buffer is received,\nbrowserinterface.register_handle_data(handle)\n# You start the module, so it will connects to WSAudio, and listen so the browser will be able to connect\nbrowserinterface.start()\n\n# Finally you start the callbacks blocking infinite loop\n# All code below will not be executed\n# This mecanism ensures the callbacks you specified are called from the main thread\n# If you forget this call, your callbacks will never be called!\nbrowserinterface.loop_callbacks()  In the following, when we talk about functions and variables, they all come from the module  browserinterface , so you must prefix them with  browserinterface. .", 
            "title": "How it works"
        }, 
        {
            "location": "/python-reference/#if-the-browser-is-not-needed", 
            "text": "If you run your own Python script and don't need the browser (to display the output), you have to set the variable  inform_browser  to false.\nIn that case, you also have to specify the IP address of the board, using the variable  board_ip  (when you use the browser, it directly communicate to your script the IP address of the board, so you don't need to specify it).  browserinterface.inform_browser = False\nbrowserinterface.board_ip = '10.1.2.3'  This must be done at the very beginning, before you  start()  the module.", 
            "title": "If the browser is not needed"
        }, 
        {
            "location": "/python-reference/#reading-the-configuration", 
            "text": "Four variables contain the configuration:   rate : the rate in bits/second;  channels : the number of channels;  buffer_frames : the number of audio frames contained in one buffer;  volume : the volume between 0 and 100.   These are read-only, and you must not change them.", 
            "title": "Reading the configuration"
        }, 
        {
            "location": "/python-reference/#receiving-configuration-changes", 
            "text": "When you start your script, the four previous variables will still be uninitialized, because the module did not received the configuration yet.\nPlus, sometimes, a configuration change can happen.  You can register a callback to receive the configuration, when it first arrives, and each time it changes, using  register_when_new_config(callback) .\nYour callback function must accept four parameters:  callback(buffer_frames, rate, channels, volume) .  If you have some variables to initialize, depending on the audio configuration,  it is safer to do it in your callback .  def my_function(buffer_frames, rate, channels, volume):\n    print  New config received: buffer_frames, rate, channels, volume \n    print buffer_frames, rate, channels, volume\n\nbrowserinterface.register_when_new_config(my_function)", 
            "title": "Receiving configuration changes"
        }, 
        {
            "location": "/python-reference/#changing-the-configuration", 
            "text": "You can change the configuration using the method  change_config(rate, channels, buffer_frames, volume) .  browserinterface.change_config(rate=44100, channels=2, buffer_frames=2048, volume=90)", 
            "title": "Changing the configuration"
        }, 
        {
            "location": "/python-reference/#receiving-the-audio-streams", 
            "text": "You can define a function that will be called each time a new audio buffer is received, by registering it:  def my_function(buffer):\n    print  Buffer received , len(buffer)\nbrowserinterface.register_handle_data(my_function)  The parameter  buffer  will contain a 2D numpy array of size  (buffer_frames, channels)  containing 16 bits integers (between -32 767 and +32 767).  An example with 5 frames per buffer and 2 channels:  np.array([\n  [100, 300],\n  [80, 240],\n  [130, 0],\n  [-800, 123],\n  [-400, 0]\n], dtype=np.int16)", 
            "title": "Receiving the audio streams"
        }, 
        {
            "location": "/python-reference/#recording-audio", 
            "text": "You can ask the Python module to record a certain audio duration for you, and to call the callback you specified, using the method  record_audio(duration, callback)  with  duration  in milliseconds.\nThe recording starts just after you called the method.  The function  callback  you specified must accept one parameter  buffer  (which will follow the same structure than above).\nPay attention that  buffer  will not be exactly of the duration you specified, but can be slightly longer.  def my_function(buffer):\n    print  Audio has been recorded , len(buffer)\n\nbrowserinterface.record_audio(5000, my_function) # my_function will be called after 5 seconds\nbrowserinterface.record_audio(15000, my_function) # my_function will be called after 15 seconds", 
            "title": "Recording audio"
        }, 
        {
            "location": "/python-reference/#sending-audio", 
            "text": "It is possible to send a new audio stream to the browser so it will play it.\nThe configuration must be exactly the same as the input buffer (same number of channels, same rate, same number of frames per buffer).  The method  send_audio(buffer)  accepts a 2D Numpy array, following the same format as the input.", 
            "title": "Sending audio"
        }, 
        {
            "location": "/python-reference/#using-the-data-handlers", 
            "text": "After you performed some algorithms on the audio streams, you may want to display some outputs, like charts, histograms or new audio streams.\nWhat you have to do is to send the data you want to display to a  data handler  of the webapp.\nYou have two simple steps to do:   You create a new data handler using the function  add_handler(name, type, parameters)  which returns an object representing this new instance;  You send data to this instance using its method  send_data(data) .   Once you call the function  add_handler , a new tab will be created in the webapp, with the name  name  you specified, and the chart/plot/audio player will appear inside.\nYou can use the part  Data Handlers  to see which  types  of data handlers exist, which parameters are supported, and which structure the  data  you send must follow.", 
            "title": "Using the data handlers"
        }, 
        {
            "location": "/data-handlers/", 
            "text": "Definition\n\n\nA data handler is an object in the webapp which can be used to handle some data.\n\n\nTypically, they are used to vizualise the output of the program written by the user, which takes into input the audio streams, and could want to draw some charts as a result.\nSeveral data handlers come with the project, but you can also easily write your own, as explained.\n\n\nThere are two main steps when using a data handler:\n\n\n\n\nYou create it, with some configuration information;\n\n\nYou send data to it.\n\n\n\n\nExample\n\n\nYou can use the data handlers from your Python code (it is defined in more details in the Python part reference):\n\n\nimport browserinterface\nimport time\nimport random\n\nbrowserinterface.start()\n\n# First, we create our handlers\n# First we precise the name, then the type, and third the possible parameters\n## A line chart, with two series\nc1 = browserinterface.add_handler(\nFirst chart - Line\n, 'base:graph:line', {'xName': 'Name of x axis', 'series': [{'name': 'First serie'}, {'name': 'Second serie'}]})\n## A plot chart, with one serie\nc2 = browserinterface.add_handler(\nSecond chart - Plot\n, 'base:graph:plot', {'xName': 'Name of super x axis', 'series': [{'name': 'Only serie'}]})\n## A polar chart, with one serie\nc3 = browserinterface.add_handler(\nThird chart - Polar\n, 'base:polar:area', {'title': 'Awesome polar chart', 'series': ['Intensity'], 'legend': {'from': 0, 'to': 360, 'step': 10}})\n\n# Then we can send some data to the different handlers\nc1.send_data({'add': [{'x': [1, 2, 3, 4], 'y': [89, 70, 40, 2, 3]}, {'x': [1, 2, 3, 4], 'y': [39, 20, -2, 4]}]})\nc2.send_data({'add': [{'x': [10, 30, 40, 70], 'y': [100, 234, 90, 23]}]})\n\nfor i in range(5, 40):\n  c1.send_data({'add': [{'x': [i], 'y': [20+i*5*random.random()]}, {'x': [i], 'y': [i*5*random.random()]}]})\n  c3.send_data([{'append': (200+i*3)*10}])\n  time.sleep(1)\n\n\n\n\nDataHandler: draw classic charts\n\n\nThis handler can be used to draw line charts, histograms.\nThere are always 2D charts, with an x axis and an y axis.\n\n\n\n\n\n\n\n\nTypes\n\n\n\n\nbase:graph:line\n: a line chart;\n\n\nbase:graph:area\n: an area chart;\n\n\nbase:graph:bar\n: an histogram;\n\n\nbase:graph:plot\n: a plot chart.\n\n\n\n\nConfiguration\n\n\nThe following options are accepted during the creation:\n\n\n\n\nxName\n (string): name of the x axis;\n\n\nseries\n (array[object]): parameters (name, color) of the different series. \nThis parameter fixes the number of series to display.\n The object representing a serie can have the following keys:\n\n\nname\n (string) [optional]: name of the serie;\n\n\ncolor\n (string) [optional]: color for the serie. Can be a CSS name (\nblue\n, \nred\n, \nsteelblue\n, \ngreen\n, \nlightblue\n...) or a rgba value (\nrgba(192,132,255,0.3)\n).\n\n\n\n\n\n\nmin\n (number) [optional]: minimum value for y;\n\n\nmax\n (number) [optional]: maximum value for y;\n\n\nLimit the number of points displayed. When the limit is reached, the first values are deleted, and all the graph is \"translated\":\n\n\nxLimitNb\n (integer): maximum number of points to display.\n\n\n\n\n\n\n\n\nSending data\n\n\nAdding points\n\n\nYou can add new points to each series:\n\n\n{\n  \nadd\n: [\n    {\n      \nx\n: [3, 4],\n      \ny\n: [39, 21]\n    },\n    {\n      \nx\n: [3, 4],\n      \ny\n: [11, 32.5]\n    }\n  ]\n}\n\n\n\n\nThe size of the array \nadd\n must be the number of series (specified during the creation).\n\n\nReplacing all the points\n\n\nYou can also replace all the points of all the series:\n\n\n{\n  \nreplace\n: [\n    {\n      \nx\n: [0, 1, 2, 3, 4],\n      \ny\n: [8, 1, 3, 0, 2]\n    },\n    {\n      \nx\n: [0, 1, 2, 3, 4],\n      \ny\n: [21, 18, 17, 13, 10]\n    }\n  ]\n}\n\n\n\n\nDataHandler: draw polar charts\n\n\nThis handler can draw polar charts.\n\n\n\n\n\n\nTypes\n\n\n\n\nbase:polar:line\n: a line polar chart;\n\n\nbase:polar:area\n: an area polar chart.\n\n\n\n\nConfiguration\n\n\nThe following options are accepted during the creation:\n\n\n\n\ntitle\n (string): name of the chart;\n\n\nseries\n (array[string]): names of the different series. \nThis parameter fixes the number of series to display\n;\n\n\nlegend\n (object): defines the scale and contains the following parameters:\n\n\nfrom\n (number): the value corresponding to a start from the north;\n\n\nto\n (number): the value corresponding to the arrival to the north after one revolution;\n\n\nstep\n (number): the size of the subdivision.\n\n\n\n\n\n\n\n\nSending data\n\n\nAdding an entry\n\n\nYou can add new data to each serie:\n\n\n[\n  {\nappend\n: 10},\n  {\nappend\n: 4},\n  {\nappend\n: 43}\n]\n\n\n\n\nThe new values will be pushed at the end of previous data of each serie.\nThe size of the array must be the number of series (specified during the creation).\n\n\nReplacing all entries\n\n\nYou can replace all data at once:\n\n\n[\n  {\nreplace\n: [3, 5, 1, 1, 4]},\n  {\nreplace\n: [1, 7, 3.4, 2.2, 2]},\n  {\nreplace\n: [2, 1, 3.8, 3.9, 4]}\n]\n\n\n\n\nThe size of the array must be the number of series (specified during the creation).\n\n\nDataHandler: draw heatmaps\n\n\nThis handler can draw heatmaps.\n\n\n\n\nTypes\n\n\n\n\nbase:heatmap\n: a heatmap.\n\n\n\n\nConfiguration\n\n\nThe following options are accepted during the creation:\n\n\n\n\nmin\n (number): the value corresponding to the minimum (which will be blue);\n\n\nmax\n (number): the value corresponding to the maximum (which will be red).\n\n\n\n\nSending data\n\n\nReplacing all entries\n\n\nYou can replace all data at once by sending a 2D-array.\nEach array corresponds to a row and contains numbers.\n\n\n[\n  [2, 3, 4, 0], // first row of the image\n  [1, 0, 0, 1], // second row of the image\n  [3, 4, 4, 1], // last row of the image\n]\n\n\n\n\nWrite your own data handler\n\n\nFrom a code point of view, a data handler is a class, from which instances are created on demand.\nBecause we are talking about JavaScript, we are not working with a real class, but with a function returning an object.\n\n\nDefining your data handler\n\n\nWhen instantiated, two parameters will be given to your function:\n\n the html element you can use to display things;\n\n the \nparameters\n object specified by the user.\n\n\nYour function must return an objet with a property/method \nnewData\n that will be called with the \ndata\n object specified by the user.\n\n\nfunction myDataHandler(html, parameters) {\n  // html is the DOM element you can use\n  // Here we just append to this html element the parameters object\n  $(html).append(JSON.stringify(parameters) + '\nbr /\n');\n\n  // We must return an object with a method newData\n  return {\n    newData: function (data) {\n      // This code will be executed each time data is sent to this data handler\n      $(html).append(JSON.stringify(data) + '\nbr /\n');\n    }\n  }\n}\n\n\n\n\nRegistering your data handler\n\n\nThen, you have to choose a type for your data handler and to register it:\n\n\ndataHandlers.registerNewType('customtype', myDataHandler);\n\n\n\n\nThe data handler can be registered by adding the above line to the file \njs/myHandlers.js\n.\n\n\nUsing it\n\n\nYou can use it from the Python code like any other data handler:\n\n\nimport browserinterface\nmyHandlerInstance = browserinterface.add_handler(\nCustom thing\n, 'customtype', {'param1': True, 'param2': 'hello', 'param3': [0, 1, 2]})\nmyHandlerInstance.send_data({'newData': {'i': i}})\nmyHandlerInstance.send_data(['an', 'array', 'this', 'time'])", 
            "title": "Data Handlers"
        }, 
        {
            "location": "/data-handlers/#definition", 
            "text": "A data handler is an object in the webapp which can be used to handle some data.  Typically, they are used to vizualise the output of the program written by the user, which takes into input the audio streams, and could want to draw some charts as a result.\nSeveral data handlers come with the project, but you can also easily write your own, as explained.  There are two main steps when using a data handler:   You create it, with some configuration information;  You send data to it.", 
            "title": "Definition"
        }, 
        {
            "location": "/data-handlers/#example", 
            "text": "You can use the data handlers from your Python code (it is defined in more details in the Python part reference):  import browserinterface\nimport time\nimport random\n\nbrowserinterface.start()\n\n# First, we create our handlers\n# First we precise the name, then the type, and third the possible parameters\n## A line chart, with two series\nc1 = browserinterface.add_handler( First chart - Line , 'base:graph:line', {'xName': 'Name of x axis', 'series': [{'name': 'First serie'}, {'name': 'Second serie'}]})\n## A plot chart, with one serie\nc2 = browserinterface.add_handler( Second chart - Plot , 'base:graph:plot', {'xName': 'Name of super x axis', 'series': [{'name': 'Only serie'}]})\n## A polar chart, with one serie\nc3 = browserinterface.add_handler( Third chart - Polar , 'base:polar:area', {'title': 'Awesome polar chart', 'series': ['Intensity'], 'legend': {'from': 0, 'to': 360, 'step': 10}})\n\n# Then we can send some data to the different handlers\nc1.send_data({'add': [{'x': [1, 2, 3, 4], 'y': [89, 70, 40, 2, 3]}, {'x': [1, 2, 3, 4], 'y': [39, 20, -2, 4]}]})\nc2.send_data({'add': [{'x': [10, 30, 40, 70], 'y': [100, 234, 90, 23]}]})\n\nfor i in range(5, 40):\n  c1.send_data({'add': [{'x': [i], 'y': [20+i*5*random.random()]}, {'x': [i], 'y': [i*5*random.random()]}]})\n  c3.send_data([{'append': (200+i*3)*10}])\n  time.sleep(1)", 
            "title": "Example"
        }, 
        {
            "location": "/data-handlers/#datahandler-draw-classic-charts", 
            "text": "This handler can be used to draw line charts, histograms.\nThere are always 2D charts, with an x axis and an y axis.", 
            "title": "DataHandler: draw classic charts"
        }, 
        {
            "location": "/data-handlers/#types", 
            "text": "base:graph:line : a line chart;  base:graph:area : an area chart;  base:graph:bar : an histogram;  base:graph:plot : a plot chart.", 
            "title": "Types"
        }, 
        {
            "location": "/data-handlers/#configuration", 
            "text": "The following options are accepted during the creation:   xName  (string): name of the x axis;  series  (array[object]): parameters (name, color) of the different series.  This parameter fixes the number of series to display.  The object representing a serie can have the following keys:  name  (string) [optional]: name of the serie;  color  (string) [optional]: color for the serie. Can be a CSS name ( blue ,  red ,  steelblue ,  green ,  lightblue ...) or a rgba value ( rgba(192,132,255,0.3) ).    min  (number) [optional]: minimum value for y;  max  (number) [optional]: maximum value for y;  Limit the number of points displayed. When the limit is reached, the first values are deleted, and all the graph is \"translated\":  xLimitNb  (integer): maximum number of points to display.", 
            "title": "Configuration"
        }, 
        {
            "location": "/data-handlers/#sending-data", 
            "text": "", 
            "title": "Sending data"
        }, 
        {
            "location": "/data-handlers/#adding-points", 
            "text": "You can add new points to each series:  {\n   add : [\n    {\n       x : [3, 4],\n       y : [39, 21]\n    },\n    {\n       x : [3, 4],\n       y : [11, 32.5]\n    }\n  ]\n}  The size of the array  add  must be the number of series (specified during the creation).", 
            "title": "Adding points"
        }, 
        {
            "location": "/data-handlers/#replacing-all-the-points", 
            "text": "You can also replace all the points of all the series:  {\n   replace : [\n    {\n       x : [0, 1, 2, 3, 4],\n       y : [8, 1, 3, 0, 2]\n    },\n    {\n       x : [0, 1, 2, 3, 4],\n       y : [21, 18, 17, 13, 10]\n    }\n  ]\n}", 
            "title": "Replacing all the points"
        }, 
        {
            "location": "/data-handlers/#datahandler-draw-polar-charts", 
            "text": "This handler can draw polar charts.", 
            "title": "DataHandler: draw polar charts"
        }, 
        {
            "location": "/data-handlers/#types_1", 
            "text": "base:polar:line : a line polar chart;  base:polar:area : an area polar chart.", 
            "title": "Types"
        }, 
        {
            "location": "/data-handlers/#configuration_1", 
            "text": "The following options are accepted during the creation:   title  (string): name of the chart;  series  (array[string]): names of the different series.  This parameter fixes the number of series to display ;  legend  (object): defines the scale and contains the following parameters:  from  (number): the value corresponding to a start from the north;  to  (number): the value corresponding to the arrival to the north after one revolution;  step  (number): the size of the subdivision.", 
            "title": "Configuration"
        }, 
        {
            "location": "/data-handlers/#sending-data_1", 
            "text": "", 
            "title": "Sending data"
        }, 
        {
            "location": "/data-handlers/#adding-an-entry", 
            "text": "You can add new data to each serie:  [\n  { append : 10},\n  { append : 4},\n  { append : 43}\n]  The new values will be pushed at the end of previous data of each serie.\nThe size of the array must be the number of series (specified during the creation).", 
            "title": "Adding an entry"
        }, 
        {
            "location": "/data-handlers/#replacing-all-entries", 
            "text": "You can replace all data at once:  [\n  { replace : [3, 5, 1, 1, 4]},\n  { replace : [1, 7, 3.4, 2.2, 2]},\n  { replace : [2, 1, 3.8, 3.9, 4]}\n]  The size of the array must be the number of series (specified during the creation).", 
            "title": "Replacing all entries"
        }, 
        {
            "location": "/data-handlers/#datahandler-draw-heatmaps", 
            "text": "This handler can draw heatmaps.", 
            "title": "DataHandler: draw heatmaps"
        }, 
        {
            "location": "/data-handlers/#types_2", 
            "text": "base:heatmap : a heatmap.", 
            "title": "Types"
        }, 
        {
            "location": "/data-handlers/#configuration_2", 
            "text": "The following options are accepted during the creation:   min  (number): the value corresponding to the minimum (which will be blue);  max  (number): the value corresponding to the maximum (which will be red).", 
            "title": "Configuration"
        }, 
        {
            "location": "/data-handlers/#sending-data_2", 
            "text": "", 
            "title": "Sending data"
        }, 
        {
            "location": "/data-handlers/#replacing-all-entries_1", 
            "text": "You can replace all data at once by sending a 2D-array.\nEach array corresponds to a row and contains numbers.  [\n  [2, 3, 4, 0], // first row of the image\n  [1, 0, 0, 1], // second row of the image\n  [3, 4, 4, 1], // last row of the image\n]", 
            "title": "Replacing all entries"
        }, 
        {
            "location": "/data-handlers/#write-your-own-data-handler", 
            "text": "From a code point of view, a data handler is a class, from which instances are created on demand.\nBecause we are talking about JavaScript, we are not working with a real class, but with a function returning an object.", 
            "title": "Write your own data handler"
        }, 
        {
            "location": "/data-handlers/#defining-your-data-handler", 
            "text": "When instantiated, two parameters will be given to your function:  the html element you can use to display things;  the  parameters  object specified by the user.  Your function must return an objet with a property/method  newData  that will be called with the  data  object specified by the user.  function myDataHandler(html, parameters) {\n  // html is the DOM element you can use\n  // Here we just append to this html element the parameters object\n  $(html).append(JSON.stringify(parameters) + ' br / ');\n\n  // We must return an object with a method newData\n  return {\n    newData: function (data) {\n      // This code will be executed each time data is sent to this data handler\n      $(html).append(JSON.stringify(data) + ' br / ');\n    }\n  }\n}", 
            "title": "Defining your data handler"
        }, 
        {
            "location": "/data-handlers/#registering-your-data-handler", 
            "text": "Then, you have to choose a type for your data handler and to register it:  dataHandlers.registerNewType('customtype', myDataHandler);  The data handler can be registered by adding the above line to the file  js/myHandlers.js .", 
            "title": "Registering your data handler"
        }, 
        {
            "location": "/data-handlers/#using-it", 
            "text": "You can use it from the Python code like any other data handler:  import browserinterface\nmyHandlerInstance = browserinterface.add_handler( Custom thing , 'customtype', {'param1': True, 'param2': 'hello', 'param3': [0, 1, 2]})\nmyHandlerInstance.send_data({'newData': {'i': i}})\nmyHandlerInstance.send_data(['an', 'array', 'this', 'time'])", 
            "title": "Using it"
        }, 
        {
            "location": "/acknowledgements/", 
            "text": "Python examples\n\n\nThe webapp includes several cool Python examples (for direction of arrival or speech detection among others).\nThey are not from me, but come from Eric Bezzam and Robin Scheibler (LCAV, EPFL, Lausanne).\n\n\nVendors\n\n\nTo have something plug-and-play, some libraries are directly included in the repository:\n\n\n\n\nBootstrap;\n\n\nd3;\n\n\njQuery;\n\n\nLodash;\n\n\nKeymaster\n;\n\n\nMicroPolar\n;\n\n\nRecorderjs\n;\n\n\nRickshaw\n;\n\n\nCloud9 ACE\n.", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/acknowledgements/#python-examples", 
            "text": "The webapp includes several cool Python examples (for direction of arrival or speech detection among others).\nThey are not from me, but come from Eric Bezzam and Robin Scheibler (LCAV, EPFL, Lausanne).", 
            "title": "Python examples"
        }, 
        {
            "location": "/acknowledgements/#vendors", 
            "text": "To have something plug-and-play, some libraries are directly included in the repository:   Bootstrap;  d3;  jQuery;  Lodash;  Keymaster ;  MicroPolar ;  Recorderjs ;  Rickshaw ;  Cloud9 ACE .", 
            "title": "Vendors"
        }
    ]
}